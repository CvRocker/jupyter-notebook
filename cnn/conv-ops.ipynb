{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requirments:\n",
    " - python >= 3.8.5\n",
    " - numpy >= 1.20.1\n",
    " - torch >= 1.7.1\n",
    " - ~~- torchvision = 0.8.2~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.8.5\n",
      "numpy: 1.20.1\n",
      "torch: 1.7.1\n",
      "torchvision: 0.8.2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2021/2/25 14:33\n",
    "# @Author  : xujian\n",
    "# @FileName: conv-ops.ipynb\n",
    "# @Software: jupyter notebook\n",
    "# @Blog    ：\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# python 版本\n",
    "print(f'python: {platform.python_version()}')\n",
    "\n",
    "# numpy 版本\n",
    "print(f'numpy: {np.__version__}')\n",
    "\n",
    "# torch & torchvision 版本\n",
    "print(f'torch: {torch.__version__}')\n",
    "print(f'torchvision: {torchvision.__version__}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 卷积运算\n",
    "## 2D卷积（conv）\n",
    "\n",
    "$Y = W*X + bias$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### img2col 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2col(input, out_h, out_w, k_h, k_w, stride):\n",
    "    \"\"\"\n",
    "    :param input: input image, format: NCHW, (batch, channel, height, width)\n",
    "    :param out_h: output image height\n",
    "    :param out_w: output image width\n",
    "    :param k_h: filter kernel height\n",
    "    :param k_w: filter kernel width\n",
    "    :param stride: filter stride\n",
    "    :return: output: coled-image, format: batch, channel, k_w*k_w, out_h*out_w)\n",
    "    \"\"\"\n",
    "    # get input dims\n",
    "    batch, channel, in_h, in_w = input.shape\n",
    "    \n",
    "    # init output (cols)\n",
    "    output = np.zeros((batch, channel, k_h*k_w, out_h*out_w))\n",
    "   \n",
    "    # init conv h/w index\n",
    "    conv_h_idx = 0\n",
    "    conv_w_idx = 0\n",
    "    \n",
    "    for i in range(batch):\n",
    "        for j in range(channel):\n",
    "            # for each channel, scan for left-top\n",
    "            # reset conv h/w index\n",
    "            conv_h_idx = 0\n",
    "            conv_w_idx = 0\n",
    "            for k in range(out_h*out_w):\n",
    "                if (conv_w_idx + k_w) > in_w:\n",
    "                    # end of the col, shift to the next row by stride\n",
    "                    conv_w_idx = 0\n",
    "                    conv_h_idx += stride\n",
    "                output[i, j, :, k] = input[i, j, conv_h_idx:conv_h_idx+k_h, conv_w_idx:conv_w_idx+k_w].flatten()\n",
    "                conv_w_idx += stride\n",
    "                \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要说明的是，卷积操作需要对所有channel的数据进行求和（大部分彩色图片都是3通道的，上图示例只显示了单通道的情况），但是池化操作需要分开计算各个channel的数据。考虑到复用问题，上面的`img2col`函数也是每个通道分开处理的，这样可以直接应用于池化操作。在卷积操作时需要对`img2col`输出的各个通道的数据进行合并。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D卷积前向操作\n",
    "conv2d_forward 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_forward(input, weights, bias, stride, pad):\n",
    "    \"\"\"\n",
    "    :param input   : input image, format: NCHW, (batch, channel, height, width)\n",
    "    :param weights  : convolution filter weightss, format: NCHW, (count, channel, height, width)\n",
    "    :param bias    : bias\n",
    "    :param stride  : stride\n",
    "    :param pad     : pad\n",
    "    :return: output: conved image, format: (batch, channel, height, width)  channel = weights.shape[0]\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, channel, in_h, in_w = input.shape\n",
    "    count, channel, k_h, k_w = weights.shape\n",
    "    \n",
    "    # calculate the output height & weights\n",
    "    out_h = int((in_h + pad - k_h)/stride) + 1\n",
    "    out_w = int((in_w + pad - k_w)/stride) + 1\n",
    "        \n",
    "    # padding\n",
    "    pad_input = np.pad(input, ((0,0),(0,0),(int(pad/2),pad-int(pad/2)),(int(pad/2),pad-int(pad/2))))\n",
    "    # new input height&weights\n",
    "    in_h += pad\n",
    "    in_w += pad\n",
    "    \n",
    "    \n",
    "    # img2col\n",
    "    col_input = img2col(pad_input, out_h, out_w, k_h, k_w, stride)\n",
    "    \n",
    "    # concat channel vis col-dim\n",
    "    # reshape col_input to [batch, (channel*k_h*h*w), out_h*out_w]\n",
    "    col_input = col_input.reshape(col_input.shape[0], -1, col_input.shape[3])\n",
    "    \n",
    "    # reshape kernel to [group-count, channel*k_h*h*w]\n",
    "    weights_flatten = weights.reshape(weights.shape[0], -1)\n",
    "    \n",
    "    # copmute convolution\n",
    "    # output: [batch, channel, out_h*out_w]\n",
    "    output = weights_flatten @ col_input + bias.reshape(-1, 1)\n",
    "    \n",
    "    # reshape output to [batch, channel, height, width]\n",
    "    output = output.reshape(output.shape[0], output.shape[1], out_h, out_w)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D卷积前向操作-测试验证程序：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff is 4.5616584365519575e-06\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# input image\n",
    "input = np.random.randn(1,1,5,5)\n",
    "\n",
    "#******** conv params *****************#\n",
    "# conv params\n",
    "# filter kernel\n",
    "weights = np.random.randn(2,1,3,3)\n",
    "# bias\n",
    "# bias = np.random.randn(weights.shape[0], weights.shape[1], 1)\n",
    "bias = np.zeros((weights.shape[0]))\n",
    "# stride\n",
    "stride = 1\n",
    "# pad\n",
    "pad = 1\n",
    "\n",
    "# numpy\n",
    "output = conv2d_forward(input, weights, bias, stride, pad*2)\n",
    "\n",
    "# torch\n",
    "input_tensor = torch.Tensor(input)\n",
    "weights_tensor = torch.Tensor(weights)\n",
    "bias_tensor = torch.Tensor(bias)\n",
    "\n",
    "out_tensor = F.conv2d(input_tensor, weights_tensor, bias_tensor, stride=stride, padding=pad)\n",
    "\n",
    "# computer the diff\n",
    "diff = np.abs(output - out_tensor.numpy()).sum()\n",
    "\n",
    "print(f'diff is {diff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### col2img 函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2img(input_col, pad_h, pad_w, kernel_h, kernel_w, channel, pad, stride):\n",
    "    \"\"\"\n",
    "    :param input_col: col_image, format: (batch, channel*k_h*k_w, out_h*out_w)\n",
    "    :param out_h: output image height\n",
    "    :param out_w: output image width\n",
    "    :param k_h: filter kernel height\n",
    "    :param k_w: filter kernel width\n",
    "    :param stride: filter stride\n",
    "    :return: output: coled-image, format: batch, channel, k_w*k_w, out_h*out_w)\n",
    "    \"\"\"\n",
    "    \n",
    "    # batch\n",
    "    batch = input_col.shape[0]\n",
    "    \n",
    "    # channel\n",
    "    channel = int(input_col.shape[1]/(kernel_h*kernel_w))\n",
    "    \n",
    "    # padding input image\n",
    "    out_pad = np.zeros((batch, channel, int(pad_h), int(pad_w)))\n",
    "    \n",
    "    # split channels\n",
    "    input_sp_channel = input_col.reshape(input_col.shape[0], channel, -1, input_col.shape[2])\n",
    "    \n",
    "    col_idx = 0;\n",
    "    h_idx = 0;\n",
    "    w_idx = 0;\n",
    "    \n",
    "    out_h = int((pad_h - kernel_h)/stride) + 1\n",
    "    out_w = int((pad_w - kernel_w)/stride) + 1\n",
    "    \n",
    "    # 最朴素的实现方法，效率并不高，有大部分数据重复做了IO操作\n",
    "    for i in range(batch):\n",
    "        for j in range(channel):\n",
    "            for col_idx in range(input_col.shape[-1]):\n",
    "                if w_idx + kernel_w > pad_w:\n",
    "                    w_idx = 0\n",
    "                    h_idx += stride\n",
    "                # recover img data\n",
    "                out_pad[i, j, h_idx:h_idx+kernel_h, w_idx:w_idx+kernel_w] = input_sp_channel[i, j, :, col_idx].reshape(kernel_h, -1)\n",
    "                w_idx += stride\n",
    "                \n",
    "\n",
    "    # remove padding\n",
    "    if pad < 1:\n",
    "        out = out_pad\n",
    "    else:\n",
    "        out = out_pad[:,:,int(pad/2):-(pad-int(pad/2)),int(pad/2):-(pad-int(pad/2))]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### col2img的测试程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img2col - col2img diff is 0.0\n"
     ]
    }
   ],
   "source": [
    "# check col2img\n",
    "\n",
    "def test_col2img():\n",
    "\n",
    "    input = np.random.randn(1,1,5,5)\n",
    "    weights = np.random.rand(1,1,3,3)\n",
    "    pad = 2\n",
    "    stride = 1\n",
    "    \n",
    "    n, c, in_h, in_w = input.shape\n",
    "    n, c, k_h, k_w = weights.shape\n",
    "    \n",
    "    # out_w & out_h\n",
    "    out_h = int((in_h + pad - k_h)/stride) + 1\n",
    "    out_w = int((in_w + pad - k_w)/stride) + 1\n",
    "    \n",
    "    # padding\n",
    "    input_pad = np.pad(input, ((0,0),(0,0),(int(pad/2),pad-int(pad/2)),(int(pad/2),pad-int(pad/2))))\n",
    "                        \n",
    "    input_col = img2col(input_pad, out_h, out_w, k_h, k_w, stride)\n",
    "    \n",
    "    # concat channel vis col-dim\n",
    "    # reshape col_input to [batch, (channel*k_h*h*w), out_h*out_w]\n",
    "    input_col = input_col.reshape(input_col.shape[0], -1, input_col.shape[3])\n",
    "                    \n",
    "    input2 = col2img(input_col, int(in_h+pad), int(in_w+pad), k_h, k_w, c, pad, stride)\n",
    "                        \n",
    "    diff = (input - input2).sum()\n",
    "                        \n",
    "    print(f\"img2col - col2img diff is {diff}\")\n",
    "    \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    test_col2img()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D卷积反向传播\n",
    "\n",
    "conv2d_backward 函数\n",
    "\n",
    "(待补充... ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D反卷积（转置卷积）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weights2col 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights2col(weights, in_h, in_w, stride, pad):\n",
    "    \"\"\"\n",
    "    :param weights: format: (number, channel, kernel_h, kernel_w)\n",
    "    :param in_h: input image height\n",
    "    :param in_w: input image width\n",
    "    :param stride: filter stride\n",
    "    :param pad: padding size\n",
    "    :return: w_col: coled-weights, format: [channel*pad_h*pad_w, count*out_h*out_w]\n",
    "    \"\"\"\n",
    "    \n",
    "    # get weights params\n",
    "    count, channel, k_h, k_w = weights.shape\n",
    "    \n",
    "    # get out_h, out_w\n",
    "    out_h = int((in_h + pad - k_h)/stride) + 1\n",
    "    out_w = int((in_w + pad - k_w)/stride) + 1\n",
    "    \n",
    "    \n",
    "    # get padding_h, padding_w\n",
    "    pad_h = in_h + pad\n",
    "    pad_w = in_w + pad\n",
    "    \n",
    "    w_col = np.zeros((count, channel, pad_h, pad_w, out_h*out_w))\n",
    "    \n",
    "    conv_w_idx = 0\n",
    "    conv_h_idx = 0\n",
    "    \n",
    "    for i in range(count):\n",
    "        for j in range(channel):\n",
    "            # scan by channels\n",
    "            conv_w_idx = 0\n",
    "            conv_h_idx = 0\n",
    "            for k in range(out_h*out_w):\n",
    "                # end of pad cols\n",
    "                if conv_w_idx + k_w > pad_w:\n",
    "                    conv_w_idx = 0\n",
    "                    conv_h_idx += stride\n",
    "                if conv_h_idx + k_h > pad_h:\n",
    "                    conv_h_idx = 0\n",
    "                # assign weights values\n",
    "                w_col[i, j, conv_h_idx:conv_h_idx+k_h, conv_w_idx:conv_w_idx+k_w, k] = weights[i, j, :, :]\n",
    "                conv_w_idx += stride\n",
    "    \n",
    "    \"\"\"\n",
    "    previous：\n",
    "    weights的count（output_channel）仍是独立维度，\n",
    "    \n",
    "    # reshape to  [count, channel, pad_h*pad_w, out_h*out_w]\n",
    "    w_col = w_col.reshape(w_col.shape[0], w_col.shape[1], -1, w_col.shape[-1])  \n",
    "    \n",
    "    # contact channels, reshape to [count, channel*pad_h*pad_w, out_h*out_w]\n",
    "    w_col = w_col.reshape(w_col.shape[0], -1, w_col.shape[3])\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    current:\n",
    "    weights的count（output_channel）和最后一维contact\n",
    "    !!! remaining speed test @auther\n",
    "    \"\"\"\n",
    "    \n",
    "    # transpose to  [channel, pad_h, pad_w, count, out_h*out_w]\n",
    "    w_col = np.transpose(w_col, (1, 2, 3, 0, 4))\n",
    "    print(f'transposed2 w_col : {w_col.shape}')\n",
    "\n",
    "    # reshape to  [channel*pad_h*pad_w, count*out_h*out_w]\n",
    "    # concat channel、pad_h、pad_w\n",
    "    # concat count(new_channel)、out_h*out_w\n",
    "    w_col = w_col.reshape(-1, count*out_h*out_w)\n",
    "    \n",
    "    return w_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weights2col 的测试程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2]\n",
      "   [ 3  4]]\n",
      "\n",
      "  [[ 5  6]\n",
      "   [ 7  8]]]\n",
      "\n",
      "\n",
      " [[[11 12]\n",
      "   [13 14]]\n",
      "\n",
      "  [[15 16]\n",
      "   [17 18]]]]\n",
      "transposed2 w_col : (2, 3, 3, 2, 4)\n",
      "[[ 1.  0.  0.  0. 11.  0.  0.  0.]\n",
      " [ 2.  1.  0.  0. 12. 11.  0.  0.]\n",
      " [ 0.  2.  0.  0.  0. 12.  0.  0.]\n",
      " [ 3.  0.  1.  0. 13.  0. 11.  0.]\n",
      " [ 4.  3.  2.  1. 14. 13. 12. 11.]\n",
      " [ 0.  4.  0.  2.  0. 14.  0. 12.]\n",
      " [ 0.  0.  3.  0.  0.  0. 13.  0.]\n",
      " [ 0.  0.  4.  3.  0.  0. 14. 13.]\n",
      " [ 0.  0.  0.  4.  0.  0.  0. 14.]\n",
      " [ 5.  0.  0.  0. 15.  0.  0.  0.]\n",
      " [ 6.  5.  0.  0. 16. 15.  0.  0.]\n",
      " [ 0.  6.  0.  0.  0. 16.  0.  0.]\n",
      " [ 7.  0.  5.  0. 17.  0. 15.  0.]\n",
      " [ 8.  7.  6.  5. 18. 17. 16. 15.]\n",
      " [ 0.  8.  0.  6.  0. 18.  0. 16.]\n",
      " [ 0.  0.  7.  0.  0.  0. 17.  0.]\n",
      " [ 0.  0.  8.  7.  0.  0. 18. 17.]\n",
      " [ 0.  0.  0.  8.  0.  0.  0. 18.]]\n",
      "(18, 8)\n"
     ]
    }
   ],
   "source": [
    "def test_weights2col():\n",
    "\n",
    "\n",
    "    input = np.random.rand(1, 2, 3, 3)\n",
    "#     weights = np.random.rand(2, 2, 2, 2)*100\n",
    "    \n",
    "    weights = np.array([[[[1,2],[3,4]],[[5,6],[7,8]]],[[[11,12],[13,14]],[[15,16],[17,18]]]])\n",
    "    stride = 1\n",
    "    pad = 0\n",
    "        \n",
    "    n, c, in_h, in_w = input.shape\n",
    "        \n",
    "    print(weights)\n",
    "    \n",
    "    w_col = weights2col(weights, in_h, in_w, stride, pad)\n",
    "    \n",
    "    print(w_col)\n",
    "    print(w_col.shape)\n",
    "    \n",
    "test_weights2col()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D卷积前向操作(by weights)\n",
    "conv2d_forward_by_weights 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_forward_by_weights(input, weights, bias, stride, pad):\n",
    "    \"\"\"\n",
    "    :param input   : input image, format: NCHW, (batch, channel, height, width)\n",
    "    :param weights  : convolution filter weightss, format: NCHW, (w_num, channel, height, width)\n",
    "    :param bias    : bias\n",
    "    :param stride  : stride\n",
    "    :param pad     : pad\n",
    "    :return: output: conved image, format: (batch, channel, height, width)  channel = weights.shape[0]\n",
    "    \"\"\"\n",
    "    \n",
    "    batch, in_channel, in_h, in_w = input.shape\n",
    "    w_num, w_channel, k_h, k_w = weights.shape\n",
    "    \n",
    "    # check if input channel is equal to weights' number?\n",
    "    assert(in_channel == w_num),\\\n",
    "        \"input channel:{} is not equal weight w_num:{}\".format(in_channel, w_num)\n",
    "    \n",
    "    # check if bias' dim is equal to weights' number?\n",
    "    assert(bias.shape[0] == w_num),\\\n",
    "        \"bias dim:{} is not equal weight w_num:{}\".format(bias.shape[0], w_num)\n",
    "    \n",
    "    \n",
    "    # calculate the output height & weights\n",
    "    out_h = int((in_h + pad - k_h)/stride) + 1\n",
    "    out_w = int((in_w + pad - k_w)/stride) + 1\n",
    "    \n",
    "    # weight2col\n",
    "    # w_col : channel*in_h*in_w, out_h*out_w*w_num(new_channel)\n",
    "    w_col = weights2col(weights, in_h, in_w, stride, pad)\n",
    "        \n",
    "    # padding\n",
    "    input_pad = np.pad(input, ((0,0),(0,0),(int(pad/2),pad-int(pad/2)),(int(pad/2),pad-int(pad/2))))\n",
    "    # new input height&weights\n",
    "    in_h += pad\n",
    "    in_w += pad\n",
    "    \n",
    "    \n",
    "    # reshape img to [batch, 1, channel*in_h*in*w]\n",
    "    input_flatten = input_pad.reshape(input_pad.shape[0], 1, -1)\n",
    "    \n",
    "    \"\"\"\n",
    "    老方法：矩阵计算时，wights的out_channel还是独立维度，需要对input 扩充维度\n",
    "    \n",
    "    # reshape img to [batch, w_num, 1, channel*in_h*in*w]\n",
    "    input_flatten = np.expand_dims(input_flatten, 1).repeat(w_num, axis=1)\n",
    "    \n",
    "    # copmute convolution\n",
    "    # output: [batch, channel, out_h*out_w]\n",
    "    output = (input_flatten @ w_col).reshape(input.shape[0], weights.shape[0], -1)\n",
    "   \n",
    "    # add bias\n",
    "    output = output + bias.reshape(-1, 1)\n",
    "    \n",
    "    # reshape output to [batch, channel, height, width]\n",
    "    output = output.reshape(output.shape[0], output.shape[1], out_h, out_w)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    新方法：weights_col的channel，contact到out_w维度\n",
    "    \n",
    "    \"\"\"\n",
    "    # copmute convolution\n",
    "    # output: [batch, out_h*out_w*new_channel]\n",
    "    output = input_flatten @ w_col\n",
    "    \n",
    "    # reshape output to [batch, channel, out_h*out_w]\n",
    "    output = output.reshape(output.shape[0], weights.shape[0], out_h*out_w)\n",
    "    \n",
    "    # add bias which reshape to [channel, 1]\n",
    "    output = output + bias.reshape(-1, 1)\n",
    "    \n",
    "    # reshape output to [batch, channel, height, width]\n",
    "    output = output.reshape(output.shape[0], weights.shape[0], out_h, out_w)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D卷积前向（vis Weigh2col)-测试验证程序：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:(2, 3, 5, 5)\n",
      "********************\n",
      "transposed2 w_col : (3, 7, 7, 3, 25)\n",
      "output_w:(2, 3, 5, 5)\n",
      "********************\n",
      "********************\n",
      "diff is 0.01766495076360286\n",
      "diff2 is 0.017664950762636522\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# input image\n",
    "input = np.random.randn(2,3,5,5)*20\n",
    "\n",
    "#******** conv params *****************#\n",
    "# conv params\n",
    "# filter kernel\n",
    "weights = np.random.randn(3,3,3,3)*20\n",
    "# bias\n",
    "bias = np.random.randn(weights.shape[0])\n",
    "# bias = np.zeros((weights.shape[0]))\n",
    "# stride\n",
    "stride = 1\n",
    "# pad\n",
    "pad = 1\n",
    "\n",
    "# numpy\n",
    "output = conv2d_forward(input, weights, bias, stride, pad*2)\n",
    "print(f'output:{output.shape}')\n",
    "# print(output)\n",
    "print('*'*20)\n",
    "\n",
    "output_w = conv2d_forward_by_weights(input, weights, bias, stride, pad*2)\n",
    "print(f'output_w:{output_w.shape}')\n",
    "# print(output_w)\n",
    "print('*'*20)\n",
    "\n",
    "# torch\n",
    "input_tensor = torch.Tensor(input)\n",
    "weights_tensor = torch.Tensor(weights)\n",
    "bias_tensor = torch.Tensor(bias)\n",
    "\n",
    "out_tensor = F.conv2d(input_tensor, weights_tensor, bias_tensor, stride=stride, padding=pad)\n",
    "# print(out_tensor.data)\n",
    "print('*'*20)\n",
    "\n",
    "# computer the diff\n",
    "diff = np.abs(output - out_tensor.numpy()).sum()\n",
    "print(f'diff is {diff}')\n",
    "\n",
    "# computer the diff\n",
    "diff = np.abs(output_w - out_tensor.numpy()).sum()\n",
    "print(f'diff2 is {diff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D反卷积前向操作\n",
    "conv_transpose2d_forward 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose2d_forward(input, weights, bias, stride, pad):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param input   : input image, format: NCHW, (batch, channel, height, width)\n",
    "    :param weights  : convolution filter weightss, format: NCHW, (w_num, channel, height, width)\n",
    "    :param bias    : bias\n",
    "    :param stride  : stride\n",
    "    :param pad     : pad\n",
    "    :return: output: conved image, format: (batch, channel, height, width)  channel = weights.shape[0]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # same channel\n",
    "    batch, in_channel, in_h, in_w = input.shape\n",
    "    w_num, w_channel, k_h, k_w = weights.shape\n",
    "    \n",
    "    # check if input channel is equal to weights' number?\n",
    "    assert(in_channel == w_num),\\\n",
    "        \"input channel:{} is not equal weights' number:{}\".format(in_channel, w_num)\n",
    "    \n",
    "    # check if bias' dim is equal to weights' number?\n",
    "    assert(bias.shape[0] == w_num),\\\n",
    "        \"bias dim:{} is not equal weight w_num:{}\".format(bias.shape[0], w_num)\n",
    "    \n",
    "    # get out_h out_w\n",
    "    # reverse the computation for conv2d\n",
    "    out_h = (in_h - 1)*stride + k_h - pad\n",
    "    out_w = (in_w - 1)*stride + k_w - pad\n",
    "    \n",
    "    # get pad_h&pad_w\n",
    "    pad_h = out_h + pad\n",
    "    pad_w = out_w + pad\n",
    "    \n",
    "    \n",
    "    # weights trans to col, \n",
    "    # weights_col : channel*pad_h*pad_w, w_num*in_h*in_w\n",
    "    weigths_col = weights2col(weights, out_h, out_w, stride, pad)\n",
    "    print(f'weigths_col is {weigths_col.shape}')\n",
    "    \n",
    "    # transpose the weights_col to [w_num(in_channel)*in_h*in_w, out_channel*pad_h*pad_w]\n",
    "    weights_t = np.transpose(weigths_col, (1,0))\n",
    "    \n",
    "    # flatten input image to [batch, in_channel*in_h*in_w]\n",
    "    input_flatten = input.reshape(input.shape[0], -1)\n",
    "     \n",
    "    # calc the matmul result : [batch, out_channel*pad_h*pad_w]\n",
    "    output_pad = input_flatten @ weights_t \n",
    "    \n",
    "    # reshape output to [batch, out_channel, pad_h*pad_w]\n",
    "    output_pad = output_pad.reshape(output_pad.shape[0], w_channel, -1)\n",
    "        \n",
    "    # add bias\n",
    "    output_pad += bias.reshape(-1, 1)\n",
    "    \n",
    "    # reshape output to [batch, w_num, pad_h, pad_w]\n",
    "    output_pad = output_pad.reshape(output_pad.shape[0], output_pad.shape[1], pad_h, pad_w)\n",
    "    \n",
    "    # remove padding\n",
    "    if pad < 1:\n",
    "        out = output_pad\n",
    "    else:\n",
    "        out = output_pad[:,:,int(pad/2):-(pad-int(pad/2)),int(pad/2):-(pad-int(pad/2))]\n",
    "        \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D反卷积-测试验证程序：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transposed2 w_col : (3, 7, 7, 3, 25)\n",
      "weigths_col is (147, 75)\n",
      "====================\n",
      "diff is 0.0064128582784857\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# input image\n",
    "# input = np.random.randn(1,2,5,5)*10\n",
    "input = np.random.randn(3,3,5,5)*10\n",
    "# input = np.array([[[[1,2],[3,4]]]])\n",
    "\n",
    "\n",
    "#******** conv params *****************#\n",
    "# conv params\n",
    "# filter kernel\n",
    "# weights = np.random.randn(1,2,5,5)*10\n",
    "weights = np.random.randn(3,3,3,3)*10\n",
    "# weights = np.array([[[[5,6],[7,8]]]])\n",
    "\n",
    "# bias\n",
    "# bias = np.random.randn(weights.shape[0])\n",
    "bias = np.zeros(weights.shape[0])\n",
    "# stride\n",
    "stride = 1\n",
    "# pad\n",
    "pad = 1\n",
    "\n",
    "# numpy\n",
    "output = conv_transpose2d_forward(input, weights, bias, stride, pad*2)\n",
    "# print(f'output:{output.shape}')\n",
    "# print(output)\n",
    "\n",
    "# torch\n",
    "input_tensor = torch.Tensor(input)\n",
    "weights_tensor = torch.Tensor(weights)\n",
    "bias_tensor = torch.Tensor(bias)\n",
    "\n",
    "print('='*20)\n",
    "\n",
    "out_tensor = F.conv_transpose2d(input_tensor, weights_tensor, bias_tensor, stride=stride, padding=pad)\n",
    "# print(out_tensor.data)\n",
    "# computer the diff\n",
    "\n",
    "diff = np.abs(output - out_tensor.numpy()).sum()\n",
    "print(f'diff is {diff}')\n",
    "\n",
    "\n",
    "print('*'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.7",
   "language": "python",
   "name": "pytorch1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
